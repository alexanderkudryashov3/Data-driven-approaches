{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1CtgP0fKAFK"
   },
   "source": [
    "# Scoring notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrGnRVh4OJ-3"
   },
   "source": [
    "This is the scoring notebook for the data driven competition at CMF 2022. You can change cells with `### YOUR CODE HERE` line, all other cells are read-only. However, you can add new cells to organize your code in a convenient way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T20:44:47.071844Z",
     "start_time": "2022-10-27T20:44:47.068841Z"
    },
    "id": "0qzJFDQLcVCs"
   },
   "outputs": [],
   "source": [
    "!pip install statsmodels\n",
    "!pip install warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YoK81KJOJ-5"
   },
   "source": [
    "Let us load the dataset. Columns in the test (public as well as private) dataset are equivalent to the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "uqUe7aiROJ-5",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68e48247a4dd077d8413e70dea7d1bf6",
     "grade": false,
     "grade_id": "cell-7d61050afd976237",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset.zip', index_col=0, header=[0, 1])\n",
    "dataset.rename(\n",
    "    columns={\n",
    "        'Unnamed: 209_level_1': 'count',\n",
    "        'Unnamed: 210_level_1': 'price',\n",
    "    },\n",
    "    level = 1,\n",
    "    inplace = True\n",
    ")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T13:58:28.907237Z",
     "start_time": "2022-10-29T13:58:28.901231Z"
    },
    "deletable": false,
    "editable": false,
    "id": "sIGbu6FEeVKw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3cd7324549c0b91b6c48f901dad73a86",
     "grade": false,
     "grade_id": "cell-170d40d54ca69e5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(\n",
    "        self, \n",
    "        dataframe: pd.DataFrame, \n",
    "        window_size: int, \n",
    "        step_size: int,\n",
    "        horizon: int,\n",
    "        first_pred: int\n",
    "    ):\n",
    "        self.df = dataframe\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "        self.horizon = horizon\n",
    "        self.first_pred = first_pred\n",
    "        assert self.first_pred > self.window_size\n",
    "        feat_idx = []\n",
    "        target_idx = []\n",
    "        for i in range(self.first_pred, self.df.shape[0], self.step_size):\n",
    "            feat_idx.append(range(i-self.horizon-self.window_size+1, i-self.horizon+1))\n",
    "            target_idx.append(i)\n",
    "        self.feat_idx = feat_idx\n",
    "        self.target_idx = target_idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.feat_idx)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.iter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.iter < len(self.feat_idx):\n",
    "            feat = self.df.iloc[self.feat_idx[self.iter]]\n",
    "            target = self.df.iloc[self.target_idx[self.iter], -1]\n",
    "            self.iter += 1\n",
    "            return feat, target\n",
    "        else:\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CDyDvVSOJ-6"
   },
   "source": [
    "Column **price** represents the price at moment **t**. The task is to predict **price** values at moment **t+60**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T13:42:43.686484Z",
     "start_time": "2022-10-29T13:42:43.683481Z"
    },
    "id": "-ID65MhXOJ-7"
   },
   "source": [
    "The forecasting problem is defined as follows. Consider the multivariate time series of features (exogenous variables) $X_0, X_1, \\dots $ where $X_i \\in \\mathbb{R}^d$. Consider the univariate time series of targets (endogenous variables) $y_0, y_1, ...$ where $y_i \\in \\mathbb{R}$. The task is to predict the $y_{T+h}$ where $T \\in \\{1000, 1001, \\dots\\}$ is the last available time stamp and $h = 60$ is the forecasting horizon by the given _sliding window_ over pairs $(X, y)_{T-N+1}, (X, y)_{T-N+2}, \\dots, (X, y)_T$ with the selected window size $1 \\leq N \\leq 1000$. The optimization problem is minimizing the mean squared error between predictions and targets.\n",
    "\n",
    "Select the window size appropriately to your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T13:58:29.952177Z",
     "start_time": "2022-10-29T13:58:29.950175Z"
    },
    "deletable": false,
    "id": "O0KZx6v2Pskf",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9f4398c0eab364af26f01b9441f9f67",
     "grade": false,
     "grade_id": "cell-61cc58a96b92ec1d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "window_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "14SgNttdOJ-9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62d485eb0d9feb886b6f4d7a3831d61e",
     "grade": false,
     "grade_id": "cell-36f1abaeb93458a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (1 <= window_size) and (window_size <= 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sv0f2CFuOJ-9"
   },
   "source": [
    "The dataloader defines the forecasting problem with the selected window size.\n",
    "\n",
    "**Remark**: first 1060 observations in both test datasets will not be scored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T13:58:31.362960Z",
     "start_time": "2022-10-29T13:58:30.675823Z"
    },
    "deletable": false,
    "editable": false,
    "id": "NsXyUoocjeQ2",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adb19a05e397dac970ee395e6ce5fb11",
     "grade": false,
     "grade_id": "cell-fbf2f36a091487d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "loader = Dataloader(\n",
    "    dataframe=dataset, \n",
    "    window_size=window_size, \n",
    "    step_size=1, \n",
    "    horizon=60, \n",
    "    first_pred=1060)\n",
    "\n",
    "for feat, target in loader:\n",
    "    break\n",
    "feat.shape, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuy9VA_ZOJ--"
   },
   "source": [
    "Define your forecasting model. You can install necessary libraries by `!pip install ... `. You can find installed packages in [requirements](https://github.com/vpozdnyakov/EvalAI/blob/master/requirements/worker.txt). Here is also CPU version of `torch==1.10.2`. Do not train the model here, instead download the weights of a pretrained model from your own cloud service, e.g. google drive by `gdown` as follows:\n",
    "\n",
    "```python\n",
    "!pip install gdown==4.2.0 -q\n",
    "url = ...\n",
    "gdown.download(url, 'model_scripted.pt', fuzzy=True)\n",
    "model = torch.jit.load('model_scripted.pt')\n",
    "```\n",
    "\n",
    "You can change the template by adding additional methods, parameters, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T13:58:31.956490Z",
     "start_time": "2022-10-29T13:58:31.953488Z"
    },
    "deletable": false,
    "id": "bvCcRraKTv4f",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3cc0e1f1f28b54852210ddb2e05d13d",
     "grade": false,
     "grade_id": "cell-b7cafa481754fe7b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class ForecastingModel():\n",
    "    def __init__(self):\n",
    "        self.models = None\n",
    "        self.j = 0\n",
    "        self.t = []\n",
    "        \n",
    "    def init2(self, prices):\n",
    "        last_ind = prices.index[-1]\n",
    "        self.models = []\n",
    "        for j in range(0,60):\n",
    "            self.t.append(len(prices[j::60])+1)\n",
    "            model=ARIMA(prices[j::60].values,order=(2,1,1), trend = 't')\n",
    "            self.models.append(model.fit())\n",
    "            if prices[j::60].index[-1] == last_ind:\n",
    "                self.j = j%60\n",
    "            \n",
    "    def forecast(self, feat):\n",
    "        prices = feat['price']\n",
    "\n",
    "        if not self.models:\n",
    "            self.init2(prices)\n",
    "            \n",
    "            \n",
    "        self.j = (self.j+1)%60   \n",
    "        \n",
    "        if np.isnan(prices.values[-1]):\n",
    "            result=self.models[self.j].predict(self.t[self.j], self.t[self.j])\n",
    "            self.models[self.j] = self.models[self.j].append(endog = result, refit = False)\n",
    "            self.t[self.j]+=1\n",
    "            return result\n",
    "        \n",
    "        self.models[self.j] = self.models[self.j].append(endog = prices.values[-1], refit = False)\n",
    "            \n",
    "        result=self.models[self.j].predict(self.t[self.j], self.t[self.j])\n",
    "        self.t[self.j]+=1   \n",
    "        \n",
    "        return result\n",
    "\n",
    "model = ForecastingModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Be99rlq0OJ-_"
   },
   "source": [
    "In **forecast** function you can do preprocessing, e.g. deletion unnecessary data or aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T13:58:33.353739Z",
     "start_time": "2022-10-29T13:58:33.351737Z"
    },
    "deletable": false,
    "id": "f9cSEgUXQjOw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef1400bc0c178ec23631536ae5705a28",
     "grade": false,
     "grade_id": "cell-58771daef4fc0219",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def forecast(feat):\n",
    "    \n",
    "    return model.forecast(feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOg43qVLOJ-_"
   },
   "source": [
    "Scoring the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T14:04:01.728985Z",
     "start_time": "2022-10-29T13:58:34.895728Z"
    },
    "deletable": false,
    "editable": false,
    "id": "BS66hiKrUaAg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a39dedc2fdf5a0ed639e9b298e31c4a3",
     "grade": true,
     "grade_id": "cell-feca7fa33d349c92",
     "locked": true,
     "points": 100,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "target = []\n",
    "for feat, _target in loader:\n",
    "    pred.append(forecast(feat))\n",
    "    target.append(_target)\n",
    "mse(pred, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nt0FqtbGOJ_A"
   },
   "source": [
    "Let us draw the forecast visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T14:04:03.182285Z",
     "start_time": "2022-10-29T14:04:01.729986Z"
    },
    "id": "rGl3CYPqWODo"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(target, label='target')\n",
    "plt.plot(pred, label='forecast')\n",
    "plt.title('Price of the asset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcgqwS-Yfvsv"
   },
   "source": [
    "Example of 1000 forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T14:04:03.301392Z",
     "start_time": "2022-10-29T14:04:03.183286Z"
    },
    "id": "9JgCdniNdrne"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(target[-100000:-99000], label='target')\n",
    "plt.plot(pred[-100000:-99000], label='forecast')\n",
    "plt.title('Price of the asset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtOAtruVfVtC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
